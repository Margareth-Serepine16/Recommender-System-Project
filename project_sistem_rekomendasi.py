# -*- coding: utf-8 -*-
"""Project_Sistem_Rekomendasi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qi9bA9gVuM1zE9_Gjs0Z3Kv0ygZVedUA

# **Proyek Sistem Rekomendasi**

- Nama : Margareth Serepine S
- Cohort ID : MC319D5X0736
- Email : margareths4167@gmail.com

# **Project Overview**

Pandemi Covid-19 pada tahun 2021 memicu lonjakan besar dalam penggunaan MOOC (Massive Open Online Courses). Dengan melimpahnya kursus online dari berbagai institusi dan platform, banyak pelajar mengalami kesulitan dalam menghadapi tantangan dalam menemukan kursus yang paling sesuai dengan kebutuhan dan tingkat keterampilan mereka. <br>

Oleh karena itu, penerapan sistem rekomendasi berbasis machine learning dalam konteks pendidikan daring tidak hanya relevan, tetapi juga sangat krusial untuk meningkatkan efektivitas pembelajaran, retensi pengguna, dan keberhasilan penyelesaian kursus. Sistem rekomendasi ini akan membantu pengguna memilih kursus dengan cara yang lebih personal dan efisien, terutama berdasarkan informasi deskripsi kursus, keterampilan, dan tingkat kesulitan.

# **Import Library**

Pada bagian ini, dilakukan proses import berbagai library dan modul yang digunakan. Berikut penjelasan masing-masing library dan fungsinya:
- `numpy as np`: Library fundamental untuk komputasi numerik di Python. Sering digunakan untuk operasi matematis, manipulasi array, dan perhitungan vektor/matriks.
- `matplotlib.pyplot as plt`: Library untuk visualisasi data dalam bentuk grafik. Digunakan untuk membuat plot seperti garis, batang, histogram, dan scatter plot.
- `pandas as pd`: Library populer untuk manipulasi dan analisis data berbasis tabel (DataFrame). Digunakan untuk membaca, menulis, dan memproses data terstruktur.
- `seaborn as sns`: Library visualisasi yang dibangun di atas matplotlib, lebih khusus untuk visualisasi statistik yang lebih estetis dan informatif.
- `os`: Digunakan untuk berinteraksi dengan sistem file dan environment.
- `re`: Modul untuk ekspresi reguler, berguna dalam pencocokan dan pemrosesan string.
- `shutil`: Digunakan untuk operasi file tingkat tinggi, seperti copy, move, dan delete file atau folder.
- `kagglehub`: Modul ini digunakan untuk mengakses model atau data dari Kaggle Hub, platform distribusi model dan dataset dari komunitas Kaggle (biasanya digunakan untuk mendownload model siap pakai).
- `collections.Counter`: Digunakan untuk menghitung frekuensi elemen dalam iterable, seperti menghitung kemunculan kata atau label.
- `sklearn.impute.SimpleImputer`: Modul dari Scikit-learn yang digunakan untuk menangani missing value (nilai kosong) dengan strategi seperti mean, median, atau modus.
- `sklearn.metrics.pairwise.cosine_similarity`: Fungsi untuk menghitung kemiripan kosinus antar vektor, biasa digunakan dalam sistem rekomendasi berbasis konten untuk mengukur kemiripan antar item atau dokumen.
- `sklearn.feature_extraction.text.TfidfVectorizer`: Digunakan untuk mengubah kumpulan teks menjadi representasi numerik berbasis TF-IDF (Term Frequency-Inverse Document Frequency), yang mencerminkan pentingnya kata dalam dokumen relatif terhadap kumpulan dokumen.
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import os, re, shutil, kagglehub

from collections import Counter
from sklearn.impute import SimpleImputer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

"""# **Load Data**

Mengunduh Dataset dari Kaggle Hub menggunakan pustaka `kagglehub`.
"""

path = kagglehub.dataset_download("khusheekapoor/coursera-courses-dataset-2021")

print("Path to dataset files:", path)

path

path = ''.join([path, '/', os.listdir(path)[0]])
path

"""Setelah dataset berhasil diunduh, langkah selanjutnya adalah menentukan path lengkap menuju folder yang berisi file dataset.

"""

df = pd.read_csv(path)
df

"""**Mengecek ukuran dataset**"""

df.shape

"""Hasil `3.522, 7)` menunjukkan bahwa dataset memiliki:

- `3.522` baris (rows): merepresentasikan kursus yang tersedia di platform Coursera.
- `7` kolom (columns): merepresentasikan fitur (kolom) atau atribut dari kursus yang tersedia.

# **Data Feature**

**Menampilkan info dari data**
"""

df.info()

"""Deskripsi fitur (kolom) :
- `Course Name` : Nama kursus,
- `University` : Universitas yang menawarkan Kursus,
- `Difficulty Level` : Tingkat Kesulitan Kursus.
- `Course Rating` : Nilai rating kursus dalam skala 0 - 5,
- `Course URL` : Tautan ke halaman kursus,
- `Course Description` : Deskripsi Kursus.
- `Skills` : Keterampilan yang terkait dengan Kursus.

Keterangan tambahan :
- Berdasarkan dataset, data yang hilang (kosong) diwakili oleh `Not Calibrated`.

# **Data Checking**

Melakukan pengecekan data untuk mengecek nilai yang hilang, dan data yang memiliki duplikasi.

**Deteksi Nilai yang Hilang/Kosong (Missing Values)**
"""

df.isnull().sum()

"""Dalam mengecek secara normal tidak ada terdeteksi data yang hilang. Namun pada dataset, diberikan keterangan bahwa data yang memiliki nilai yang hilang diberi nilai `Not Calibrated`.

Mengecek fitur (kolom) yang mengandung nilai `Not Calibrated` yang dianggap sebagai nilai yang hilang (kosong)
"""

for column in df.columns:
    count = df[column].astype(str).str.contains("Not Calibrated").sum()
    if count > 0:
        print(f'Kolom "{column}" mengandung {count} nilai "Not Calibrated"')

"""**Deteksi Data yang Duplikat**"""

df.duplicated().sum()

"""Hasil `np.int64(98)` menunjukkan ada 98 baris data yang terdeteksi sebagai duplikat.

# **Univariate Exploratory Data Analysis**
"""

df.columns

"""**Visualisasi Course Rating**"""

df['Course Rating'].value_counts()

# Menghitung frekuensi nilai Course Rating
rating_counts = df['Course Rating'].value_counts()

# Plot bar chart
plt.figure(figsize=(8,5))
sns.barplot(x=rating_counts.index, y=rating_counts.values, palette='viridis')
plt.title('Frekuensi Course Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah Kursus')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

"""Distribusi hasil :
 * Dominasi Rating Positif : Rating 4.7, 4.6, dan 4.8 merupakan yang nilai yang paling sering muncul, masing-masing dengan jumlah kursus lebih dari 600. Hal ini mencerminkan bahwa mayoritas kursus memiliki tingkat kepuasan pengguna yang sangat tinggi. Platform kemungkinan besar berhasil mempertahankan standar kualitas yang baik dalam penyediaan kursus.
 * Minimnya Kursus dengan Rating Rendah : Kursus dengan rating di bawah 4.0 jumlahnya sangat sedikit dibandingkan dengan kursus yang memiliki rating tinggi. Menunjukkan bahwa kursus dengan kualitas rendah mungkin sudah dihapus, atau pengguna memang jarang memilih kursus yang tidak populer.
 * Nilai "Not Calibrated" : Sebanyak 82 data yang memiliki label "Not Calibrated" yang artinya tidak memiliki rating. Dimana data ini secara khusus akan diganti nilainya menjadi NaN supaya dapat terdeteksi menjadi nilai yang kosong.
 * Distribusi Miring Positif (Right Skewed) : Distribusi data condong ke rating tinggi yang artinya sebagian besar kursus dinilai sangat baik, sementara hanya sedikit yang mendapat rating rendah.

**Analisis Fitur Nama Kursus dan Universitas**
"""

columns_to_plot = list(df.columns)[0:2]
for column in columns_to_plot:
  print(f"Kolom : {column}")
  print(df[column].value_counts(sort='descending'))
  print("\n")

"""Hasil :    
- Fitur Course Name (Nama) : Total 3.416 kursus unik yang dicatat dalam kolom ini dengan kursus paling populer yaitu "Google Cloud Platform Fundamentals: Core Infrastructure" yang muncul sebanyak 8 kali. Sebagian besar kursus hanya muncul sekali, menunjukkan bahwa mayoritas kursus bersifat unik. Platform memiliki beragam topik kursus, menunjukkan variasi yang besar.
- Fitur University (Universitas) : Terdapat 184 institusi/universitas yang menawarkan kursus. Dengan lima (5) universitas teratas yaitu Coursera Project Network sebanyak 562 kursus, University of Illinois at Urbana-Champaign sebanyak 138 kursus, Johns Hopkins University sebanyak 110 kursus, University of Colorado Boulder sebanyak 101 kursus, dan University of Michigan sebanyak 101 kursus. Banyak universitas/institusi hanya memiliki satu (1) kursus yang menandakan keragaman kontributor dalam platform ini.

**Visualisasi Fitur Difficulty Level**
"""

order = df['Difficulty Level'].value_counts(sort='descending').index
sns.countplot(data=df, y='Difficulty Level', order=order, palette='viridis', hue='Difficulty Level')
plt.show()

"""Distribusi hasil :
- Beginner (Pemula) merupakan tingkat kesulitan yang paling banyak, dengan jumlah lebih dari 1400 kursus. Hal ini menunjukkan bahwa platform ini sangat ramah bagi pemula.
- Advanced dan Intermediate juga memiliki representasi yang tinggi, masing-masing mendekati 1000 dan 850 kursus, menandakan adanya banyak kursus untuk pengguna yang sudah memiliki pengetahuan menengah hingga lanjut.
- Conversant (cukup menguasai) memiliki jauh lebih sedikit kursus (~200), menunjukkan bahwa label ini tidak banyak digunakan oleh pengguna/instruktur dan penyedia kursus
- Not Calibrated berjumlah sangat sedikit, yang merupakan data tidak lengkap (missing value), dan perlu ditangani pada tahap selanjutnya.

# **Data Preparation**

### Data Cleaning

**Mengubah nilai 'Not Calibrated'**
"""

df.replace("Not Calibrated", np.nan,inplace=True)

"""Data yang terdeteksi sebagai nilai `Not Calibrated` diganti menjadi `NaN` supaya saat mendeteksi 'missing value' jumlahnya dapat terdeteksi oleh sistem."""

df.isnull().sum()

"""Setelah nilai diubah, tampilan menunjukkan bahwa total missing value pada data sebanyak :    
- 50 buah pada fitur `Difficulty Level`
- 82 buah pada fitur `Course Rating`

**Mengganti Tipe Data Fitur Course Rating**
"""

df['Course Rating'] = df['Course Rating'].astype(float)

"""Mengganti tipe data Course Rating menjadi `float` untuk memastikan data dapat dianalisis, divisualisasikan, dan digunakan dalam algoritma machine learning yang memerlukan input numerik.

**Penanganan Missing Value pada Fitur Course Rating**
"""

impute = SimpleImputer(strategy="median")
df['Course Rating'] = impute.fit_transform(df[['Course Rating']])

"""Untuk mengatasi missing value pada kolom Course Rating dilakukan pengubahan nilai, yaitu mengganti nilai yang dideteksi sebagai missing value menggunakan nilai median dari seluruh data pada kolom tersebut.

**Penanganan Missing Value pada Fitur Difficulty Level**
"""

df.loc[df['Difficulty Level'].isna(), 'Difficulty Level'] = df['Difficulty Level'].mode()[0]

"""Untuk mengatasi missing value pada kolom Difficulty Level dilakukan pengubahan nilai yaitu mengganti missing value menggunakan nilai modus (mode) dari kolom tersebut karena nilai yang paling sering muncul (modus) mewakili sebagian besar data, sehingga aman digunakan sebagai pengganti nilai yang hilang.

**Menghapus Data Duplikat**
"""

df = df.drop_duplicates()

"""Menghapus semua data yang terdeteksi duplikat"""

df = df.copy()

"""**Menghapus Karakter Khusus**"""

df.loc[:, 'Course Name'] = df['Course Name'].str.replace(r'[:,\-]', ' ', regex=True)
df.loc[:, 'Course Description'] = df['Course Description'].str.replace(r'[-\.:,]', ' ', regex=True)
df.loc[:, 'Skills'] = df['Skills'].str.replace(r'[-\.:,()]', ' ', regex=True)

"""Menghapus atau mengganti karakter-karakter khusus non-alfabet seperti tanda baca pada kolom `Course Name`, `Course Description`, dan `Skills`, menjadi spasi menggunakan ekspresi reguler (regex) agar hasil representasi teks menjadi lebih bersih  agar teks lebih bersih dan mudah diproses lebih lanjut untuk pemodelan.

### Text Feature Transformation

**Fitur Gabungan Representasi Teks**
"""

df.loc[:, 'Final Col'] = df['Course Name'] + ' ' + df['Course Description'] + ' ' + df['Skills'] + ' ' + df['Difficulty Level']

"""Menggabungkan beberapa kolom seperti `Course Name`, `Course Description`, `Skills`, dan `Difficulty Level` ke dalam satu kolom baru bernama `Final Col` yang akan digunakan sebagai fitur input pada sistem rekomendasi berbasis content-based filtering dengan tujuan untuk mengintegrasikan informasi penting dari berbagai fitur menjadi satu representasi teks utuh yang akan digunakan sebagai dasar sistem rekomendasi berbasis konten."""

df

"""**Ekstraksi Fitur Teks**"""

# Inisialisasi TF-IDF vectorizer dengan stop words bahasa Inggris
vectorizer = TfidfVectorizer(stop_words='english')

# Mengisi nilai kosong dengan string kosong
df.loc[:, 'Final Col'] = df['Final Col'].fillna('')
# Membuat matriks TF-IDF dari kolom teks
tfidf_matrix = vectorizer.fit_transform(df['Final Col'])

"""Penjelasan :
- Penanganan Nilai Kosong: Sebelum mengekstraksi fitur teks, nilai kosong pada kolom Final Col diisi dengan string kosong ('') menggunakan fungsi .fillna(''). Langkah ini penting untuk mencegah error saat proses transformasi TF-IDF dan memastikan semua baris memiliki representasi teks, meskipun kosong.
- Ekstraksi Fitur Teks (TF-IDF) : Mengonversi kolom 'Final Col' menjadi vektor numerik menggunakan metode TF-IDF (Term Frequency - Inverse Document Frequency) untuk memberikan bobot terhadap kata-kata yang lebih unik dan penting dalam setiap kursus dibandingkan dengan kata-kata umum serta menghasilkan matriks representasi numerik yang akan digunakan untuk menghitung kemiripan antar kursus.

# **Modeling**

**Similarity Calculation**
"""

cosine_sim_matrix = cosine_similarity(tfidf_matrix)

"""Menghitung kemiripan antar kursus berdasarkan hasil ekstraksi fitur TF-IDF dari kolom Final Col, yang telah merepresentasikan informasi gabungan dari beberapa fitur

**Index Mapping**
"""

indices = pd.Series(df.index, index=df['Course Name']).drop_duplicates()

"""Membuat pemetaan antara `Course Name` dengan indeks baris dalam DataFrame. untuk membantu mengambil posisi kursus tertentu dalam matriks kemiripan berdasarkan nama kursus yang diberikan oleh pengguna.

**Course Recommendation**
"""

def get_recommendations(title, cosine_sim=cosine_sim_matrix):
    # Mengambil indeks dari judul yang diberikan
    idx = indices[title]

    # Menghitung skor kesamaan antara item tersebut dan semua item lainnya
    similarity_scores = list(enumerate(cosine_sim[idx]))

    # Mengurutkan berdasarkan skor kesamaan tertinggi
    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)

    # Mengambil 5 item teratas selain dirinya sendiri
    top_scores = similarity_scores[1:6]

    # Membuat tabel rekomendasi
    recommendations = pd.DataFrame({
        'Rekomendasi': df['Course Name'].iloc[[i[0] for i in top_scores]].values,
        'Similarity': [i[1] for i in top_scores]
    })

    return recommendations

"""Menghasilkan rekomendasi kursus berdasarkan kursus yang dipilih pengguna deengan memanfaatkan `cosine_sim_matrix` untuk mencari kursus-kursus lain yang paling mirip berdasarkan konten deskriptif yang sudah ditransformasikan ke dalam bentuk numerik dengan TF-IDF.

**Top 5 Recommendatiion**

Sistem rekomendasi ini mengimplementasikan fungsi `get_recommendations` yang menerima input berupa judul kursus dan mengembalikan daftar lima kursus teratas yang paling relevan berdasarkan skor kemiripan kontennya. Proses dilakukan dengan mengambil vektor dari kursus yang dipilih, menghitung skor kemiripan terhadap seluruh kursus lain, mengurutkannya, dan menampilkan lima teratas selain kursus itu sendiri.
"""

get_recommendations('Finance for Managers')

"""Hasil di atas merupakan Top 5 rekomendasi saran kursus yang relevan berdasarkan isi materi dan kesamaan fitur deskriptif `Finance for Managers`, yang berarti merekomendasikan kursus lain yang mirip dengan kursus berjudul `Finance for Managers`.

## **Evaluation**

**Metrik Evaluasi yang Digunakan**
"""

def calculate_coverage(recommendation_func, all_titles):
    recommended_items = set()

    for title in all_titles:
        try:
            recs = recommendation_func(title)
            recommended_items.update(recs['Rekomendasi'])
        except:
            continue

    total_items = df['Course Name'].nunique()
    coverage = len(recommended_items) / total_items
    return coverage

"""`Coverage` : Mengukur seberapa banyak item (kursus) dalam dataset yang muncul minimal satu kali dalam hasil rekomendasi. Sistem menghitung semua rekomendasi dari seluruh kursus, lalu menghitung proporsi kursus yang pernah direkomendasikan terhadap jumlah kursus total.

**Berdasarkan Metrik Evaluasi**
"""

all_titles = df['Course Name'].unique()
coverage_score = calculate_coverage(get_recommendations, all_titles)
print(f"Coverage: {coverage_score:.2%}")

"""Sistem berhasil merekomendasikan sekitar `91.74%` dari seluruh kursus yang tersedia dalam dataset. Ini menunjukkan bahwa sistem memiliki jangkauan yang luas dalam memberikan rekomendasi dan tidak hanya fokus pada kursus tertentu saja."""

def calculate_novelty(recommendation_func, all_titles, top_k=5):
    # Hitung popularitas item berdasarkan berapa kali muncul di rekomendasi
    recommended_items = []

    for title in all_titles:
        try:
            recs = recommendation_func(title)
            recommended_items.extend(recs['Rekomendasi'].values[:top_k])
        except:
            continue

    # Hitung popularitas: jumlah kemunculan / total rekomendasi
    item_counts = Counter(recommended_items)
    total_recs = sum(item_counts.values())
    novelty_scores = []

    for item, count in item_counts.items():
        popularity = count / total_recs
        novelty = np.log2(1 / popularity)
        novelty_scores.append(novelty)

    # Ambil rata-ratanya
    avg_novelty = np.mean(novelty_scores)
    return avg_novelty

"""`Novelty` : Mengukur sejauh mana rekomendasi yang diberikan bersifat baru atau tidak populer. Sistem menghitung frekuensi kemunculan tiap kursus dalam semua hasil rekomendasi. Semakin jarang muncul, semakin tinggi skor novelty-nya."""

novelty_score = calculate_novelty(get_recommendations, df['Course Name'].unique())
print(f"Novelty Score: {novelty_score:.4f}")

"""Skor ini menunjukkan bahwa sistem memberikan rekomendasi yang tergolong tidak populer atau belum umum, yang artinya sistem mendorong pengguna untuk menemukan kursus baru yang mungkin belum dikenal sebelumnya."""